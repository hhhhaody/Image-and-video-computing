{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "noticed-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from filterpy.kalman import KalmanFilter\n",
    "from filterpy.common import Q_discrete_white_noise\n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "wanted-engine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(x, img):\n",
    "    # Convert into binary image using thresholding\n",
    "    # Documentation for threshold: http://docs.opencv.org/modules/imgproc/doc/miscellaneous_transformations.html?highlight=threshold#threshold\n",
    "    # Example of thresholding: http://docs.opencv.org/doc/tutorials/imgproc/threshold/threshold.html\n",
    "    thres_output = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,x,-5)\n",
    "    # Find contours\n",
    "\t# Documentation for finding contours: http://docs.opencv.org/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html?highlight=findcontours#findcontours\n",
    "    contours, hierarchy = cv2.findContours(thres_output, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    return contours, thres_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alleged-memphis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_frame_differencing(prev, curr):\n",
    "    '''\n",
    "    Function that does frame differencing between the current frame and the previous frame\n",
    "    Args:\n",
    "        src The current color image\n",
    "        prev The previous color image\n",
    "    Returns:\n",
    "        dst The destination grayscale image where pixels are colored white if the corresponding pixel intensities in the current\n",
    "    and previous image are not the same\n",
    "    '''\n",
    "    dst = cv2.absdiff(prev, curr)\n",
    "    gs = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n",
    "    dst = (gs > 20).astype(np.uint8) * 255\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "normal-america",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find centers of the detected contours, return list of centers\n",
    "def find_center(contours):\n",
    "    centers = []\n",
    "    for c in contours:\n",
    "        M = cv2.moments(c)\n",
    "        if M['m00'] == 0:\n",
    "            cX = int(c[0][0][0])\n",
    "            cY = int(c[0][0][1])\n",
    "            centers.append([cX,cY])\n",
    "        else:\n",
    "            cX = int(M['m10']/M['m00'])\n",
    "            cY = int(M['m01']/M['m00'])\n",
    "            centers.append([cX,cY])\n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "minute-congo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def area(countours,thresh):\n",
    "    temp = []\n",
    "    for i in range(len(contours)):\n",
    "        (x,y,w,h) = cv2.boundingRect(contours[i])\n",
    "        if w*h >=thresh:\n",
    "            temp.append(contours[i])\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "functioning-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find match between the list of previous center positions and current center positions\n",
    "# return two list of matching indexes: p_ind, c_ind where p_ind[0] matches with c_ind[0]\n",
    "def find_match(prev,cur,thresh):\n",
    "    # calculate pairwise distance and stores into a matrix\n",
    "    cost = distance_matrix(prev,cur) \n",
    "    cost[cost>thresh]=9999\n",
    "    \n",
    "    # use the distance matrix as the cost to do the matching using Hungarian algorithm which\n",
    "    # minimizes the total cost while each row or column has at most one match\n",
    "    p_ind, c_ind = linear_sum_assignment(cost) \n",
    "    return p_ind,c_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "complex-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define each item\n",
    "class track:\n",
    "    def __init__(self, position):\n",
    "        self.color = (random.randint(50,255), random.randint(50,255), random.randint(50,255))\n",
    "        self.track = [tuple(position)]\n",
    "        self.pos = position \n",
    "        # initialize kf for the specific track\n",
    "        self.kf = KalmanFilter(dim_x=4, dim_z=2)\n",
    "        self.kf.x = position+[0,0] #initial value\n",
    "        self.kf.F = np.array([[1,0,1,0], [0,1,0,1], [0,0,1,0], [0,0,0,1]]) # linear mapping from one state to the next\n",
    "        self.kf.H = np.array([[1,0,0,0], [0,1,0,0]]) # linear mapping from prediction to observations\n",
    "        self.kf.P = 0.001 * np.eye(4) # estimate covariance matrix\n",
    "        self.kf.Q = 0.001 * np.eye(4) # Process uncertainty/noise\n",
    "        self.kf.R = 0.001 * np.eye(2) # measurement uncertainty/noise\n",
    "    \n",
    "    def predict(self):\n",
    "        self.kf.predict()\n",
    "        return self.kf.x.astype(int)[:2]\n",
    "\n",
    "        \n",
    "    def update(self,position):\n",
    "        self.kf.update(position)\n",
    "        self.pos = self.kf.x.astype(int)[:2].tolist()\n",
    "        self.track += [tuple(self.pos)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "alert-mobility",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x,y):\n",
    "    return np.sqrt((x[1]-y[1])**2 + (x[0]-y[0])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "protective-works",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bat images\n",
    "img_path = './bats/Gray'\n",
    "files = [join(img_path,f) for f in listdir(img_path) if isfile(join(img_path,f))]\n",
    "files.sort()\n",
    "img = []\n",
    "for i in range(len(files)):\n",
    "    img.append(cv2.imread(files[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "arabic-miami",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_indx = 1\n",
    "while img_indx < len(files):\n",
    "# while img_indx < 50:\n",
    "    cur = img[img_indx]\n",
    "    gray = cv2.cvtColor(cur, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.blur(gray, (5, 5))\n",
    "    contours, thres_output = threshold(105, blur)\n",
    "    contours = area(contours,71)\n",
    "    output = img[img_indx][:,:,:].copy()\n",
    "    \n",
    "\n",
    "    if img_indx == 1:\n",
    "        centers = find_center(contours)\n",
    "        tracks = [track(i) for i in centers]\n",
    "    else:\n",
    "        prev = [i.predict() for i in tracks]\n",
    "        current = find_center(contours)\n",
    "        p_ind,c_ind = find_match(prev,current,80)\n",
    "        for i in range(len(p_ind)):\n",
    "            if distance(tracks[p_ind[i]].pos,current[c_ind[i]]) > 100:\n",
    "#                 print('dist too large')\n",
    "                tracks.append(track(current[c_ind[i]]))\n",
    "            else:  \n",
    "                tracks[p_ind[i]].update(current[c_ind[i]])\n",
    "        \n",
    "        for i in range(len(current)):\n",
    "#             print('not in c_ind')\n",
    "            if i not in c_ind:\n",
    "                tracks.append(track(current[i]))\n",
    "        \n",
    "    for i in range(len(contours)):\n",
    "        boundrec = cv2.boundingRect(contours[i])\n",
    "        cv2.rectangle(output, boundrec, (0, 255, 0), 1, 8, 0)\n",
    "            \n",
    "    if (len(tracks) > 0):\n",
    "        for i in range(len(tracks)):\n",
    "            if len(tracks[i].track)>1:\n",
    "                for j in range(len(tracks[i].track)-1):\n",
    "                    cv2.line(output,tracks[i].track[j],tracks[i].track[j+1],tracks[i].color,1)\n",
    "\n",
    "        # Show in a window\n",
    "        cv2.namedWindow(\"Tracks\", cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow(\"Tracks\", output)\n",
    "        if cv2.waitKey(100)&0xFF == 27:\n",
    "            break\n",
    "    \n",
    "    img_indx += 1\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "palestinian-catering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell images\n",
    "img_path = './cells'\n",
    "files = [join(img_path,f) for f in listdir(img_path) if isfile(join(img_path,f))]\n",
    "files.sort()\n",
    "img = []\n",
    "for i in range(len(files)):\n",
    "    img.append(cv2.imread(files[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "civilian-sauce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_indx = 2\n",
    "while img_indx < len(files):\n",
    "# while img_indx < 20:\n",
    "    prev = img[img_indx-1]\n",
    "    cur = img[img_indx]\n",
    "    \n",
    "    diff = my_frame_differencing(prev, cur)\n",
    "    \n",
    "    cv2.namedWindow(\"Segmentation\", cv2.WINDOW_AUTOSIZE)\n",
    "    cv2.imshow(\"Segmentation\", diff)\n",
    "    \n",
    "    size = 10\n",
    "    element = np.ones((size,size))\n",
    "    diff = cv2.dilate(diff, element)\n",
    "    diff = cv2.dilate(diff, element)\n",
    "    \n",
    "    \n",
    "    ret, thresh = cv2.threshold(diff,20,255,cv2.THRESH_BINARY)\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    contours = area(contours,2500)\n",
    "\n",
    "    output = img[img_indx][:,:,:].copy()\n",
    "    \n",
    "    if img_indx-1 == 1:\n",
    "        centers = find_center(contours)\n",
    "        tracks = [track(i) for i in centers]\n",
    "    else:\n",
    "        prev = [i.predict() for i in tracks]\n",
    "        current = find_center(contours)\n",
    "        p_ind,c_ind = find_match(prev,current,100)\n",
    "        for i in range(len(p_ind)):\n",
    "            if distance(tracks[p_ind[i]].pos,current[c_ind[i]]) > 200:\n",
    "                tracks.append(track(current[c_ind[i]]))\n",
    "            else:  \n",
    "                tracks[p_ind[i]].update(current[c_ind[i]])\n",
    "        \n",
    "        for i in range(len(current)):\n",
    "            if i not in c_ind:\n",
    "                tracks.append(track(current[i]))\n",
    "        \n",
    "    for i in range(len(contours)):\n",
    "        boundrec = cv2.boundingRect(contours[i])\n",
    "        cv2.rectangle(output, boundrec, (0, 255, 0), 1, 8, 0)\n",
    "            \n",
    "    if (len(tracks) > 0):\n",
    "        for i in range(len(tracks)):\n",
    "            if len(tracks[i].track)>1:\n",
    "                for j in range(len(tracks[i].track)-1):\n",
    "                    cv2.line(output,tracks[i].track[j],tracks[i].track[j+1],tracks[i].color,2)\n",
    "\n",
    "        # Show in a window\n",
    "        cv2.namedWindow(\"Tracks\", cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow(\"Tracks\", output)\n",
    "        if cv2.waitKey(100)&0xFF == 27:\n",
    "            break\n",
    "    \n",
    "    img_indx += 1\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-outdoors",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
