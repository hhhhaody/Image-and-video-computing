{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "oriental-holly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CS585 HW2\n",
    "# Group member: Deyan Hao, Yirong Zhang\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "equal-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundingbox(src):\n",
    "\n",
    "    # Find contours\n",
    "\t# Documentation for finding contours: http://docs.opencv.org/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html?highlight=findcontours#findcontours\n",
    "    contours, hierarchy = cv2.findContours(src, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour_output = cv2.cvtColor(np.zeros(np.shape(src), dtype='uint8'), cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Fine largest contour\n",
    "    if (len(contours) > 0):\n",
    "        max_id = max(enumerate(contours), key=lambda x : cv2.contourArea(x[1]))[0]\n",
    "        max_size = cv2.contourArea(contours[max_id])\n",
    "        boundrec = cv2.boundingRect(contours[max_id])\n",
    "        x,y,w,h = boundrec\n",
    "\n",
    "        # Draw contours(ONLY the biggest one is drawn)\n",
    "\t    # Documentation for drawing contours: http://docs.opencv.org/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html?highlight=drawcontours#drawcontours\n",
    "        cv2.drawContours(contour_output, contours, max_id, (255, 255, 255), 2, 8)\n",
    "\n",
    "        # Documentation for drawing rectangle: http://docs.opencv.org/modules/core/doc/drawing_functions.html\n",
    "        cv2.rectangle(contour_output, boundrec, (0, 0, 255), 1, 8, 0)\n",
    "\n",
    "        # Get the moments of the largest contour to compute the centroid\n",
    "        M = cv2.moments(contours[max_id])\n",
    "        cx = int(M['m10']/M['m00'])\n",
    "        cy = int(M['m01']/M['m00'])      \n",
    "        centroid = \"centroid: \"+str(cx)+\" ,\"+str(cy)\n",
    "        \n",
    "        cv2.putText(contour_output,centroid,(100,100),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2)\n",
    "\n",
    "        \n",
    "    return contour_output,cx,cy\n",
    "    \n",
    "def my_template_match(src):\n",
    "    \n",
    "    #read the templates and convert them to grayscale image\n",
    "    five = cv2.imread('five.png')\n",
    "    five = cv2.cvtColor(five, cv2.COLOR_BGR2GRAY)\n",
    "    six = cv2.imread('six.png')\n",
    "    six = cv2.cvtColor(six, cv2.COLOR_BGR2GRAY)\n",
    "    two = cv2.imread('two.png')\n",
    "    two = cv2.cvtColor(two, cv2.COLOR_BGR2GRAY)\n",
    "    rock = cv2.imread('rock.png')\n",
    "    rock = cv2.cvtColor(rock, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    templates = [five,six,two,rock]\n",
    "    name = [\"five\",\"six\",\"two\",\"rock\"]\n",
    "    value = []\n",
    "\n",
    "    # create src image pyramids with smaller sizes\n",
    "    down1 = cv2.pyrDown(src)\n",
    "#     cv2.imwrite('down1.png',down1)\n",
    "#     print(down1.shape)\n",
    "    down2 = cv2.pyrDown(down1)\n",
    "#     cv2.imwrite('down2.png',down2)\n",
    "#     print(down2.shape)\n",
    "    down3 = cv2.pyrDown(down2)\n",
    "#     cv2.imwrite('down3.png',down3)\n",
    "#     print(down3.shape)\n",
    "    for temp in templates:\n",
    "        try:\n",
    "            res3 = cv2.matchTemplate(down3,temp,cv2.TM_CCORR_NORMED)   \n",
    "            _, max_val3, _, _ = cv2.minMaxLoc(res3)\n",
    "            \n",
    "            res2 = cv2.matchTemplate(down2,temp,cv2.TM_CCORR_NORMED)   \n",
    "            _, max_val2, _, _ = cv2.minMaxLoc(res2)          \n",
    "            \n",
    "            res1 = cv2.matchTemplate(down1,temp,cv2.TM_CCORR_NORMED)   \n",
    "            _, max_val1, _, _ = cv2.minMaxLoc(res1)  \n",
    "            \n",
    "            res = cv2.matchTemplate(src,temp,cv2.TM_CCORR_NORMED)   \n",
    "            _, max_val, _, _ = cv2.minMaxLoc(res) \n",
    "            value.append(max(max_val1,max_val2,max_val3,max_val))\n",
    "        except:\n",
    "            value.append(0)\n",
    "#     print(max(value))\n",
    "    if max(value) > 0.85:   \n",
    "        return name[value.index(max(value))]\n",
    "    else:\n",
    "        return 'not sure'\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "satellite-andrews",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from lab\n",
    "def my_skin_detect(src):\n",
    "    '''\n",
    "    BGR\n",
    "    Function that detects whether a pixel belongs to the skin based on RGB values\n",
    "    Args: \n",
    "        src The source color image\n",
    "    Returns: \n",
    "        dst The destination grayscale image where skin pixels are colored white and the rest are colored black\n",
    "    Surveys of skin color modeling and detection techniques:\n",
    "    Vezhnevets, Vladimir, Vassili Sazonov, and Alla Andreeva. \"A survey on pixel-based skin color detection techniques.\" Proc. Graphicon. Vol. 3. 2003.\n",
    "    Kakumanu, Praveen, Sokratis Makrogiannis, and Nikolaos Bourbakis. \"A survey of skin-color modeling and detection methods.\" Pattern recognition 40.3 (2007): 1106-1122.\n",
    "    '''\n",
    "    dst = np.zeros(np.shape(src)[:-1], dtype=np.uint8)\n",
    "    b,g,r = src[:,:,0],src[:,:,1],src[:,:,2]\n",
    "    mask = np.logical_and.reduce((r>95,b>40,g>20,abs(r-g)>15,r>g,r>b))\n",
    "    dst[mask]=255\n",
    "    return dst\n",
    "\n",
    "def my_frame_differencing(prev, curr):\n",
    "    '''\n",
    "    Function that does frame differencing between the current frame and the previous frame\n",
    "    Args:\n",
    "        src The current color image\n",
    "        prev The previous color image\n",
    "    Returns:\n",
    "        dst The destination grayscale image where pixels are colored white if the corresponding pixel intensities in the current\n",
    "    and previous image are not the same\n",
    "    \n",
    "    function: cv2.absdiff\n",
    "    '''\n",
    "    \n",
    "    dst = cv2.absdiff(prev, curr)\n",
    "    gs = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n",
    "    dst = (gs > 95).astype(np.uint8) * 255\n",
    "    return dst\n",
    "\n",
    "\n",
    "def my_motion_energy(mh):\n",
    "    '''\n",
    "    Function that accumulates the frame differences for a certain number of pairs of frames\n",
    "    Args:\n",
    "        mh Vector of frame difference images\n",
    "    Returns:\n",
    "        dst The destination grayscale image to store the accumulation of the frame difference images\n",
    "        \n",
    "        If a pixel has a 255 value in any of the three frames of your motion history, then the outoupt pixel will be set to 255\n",
    "    ''' \n",
    "    dst = np.zeros(np.shape(mh[0]),dtype = np.uint8)\n",
    "    mask = np.logical_and.reduce((mh[0][:,:] == 255, mh[1][:,:] == 255, mh[2][:,:] == 255,mh[3][:,:] == 255))\n",
    "    dst[mask] = 255\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rotary-banana",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esc key is pressed by user\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------\n",
    "# Reading a stream of images from a webcamera, and displaying the video\n",
    "# ----------------\n",
    "# For more information on reading and writing video: http://docs.opencv.org/modules/highgui/doc/reading_and_writing_images_and_video.html\n",
    "# open the video camera no. 0\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# if not successful, exit program\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open the video cam\")\n",
    "    sys.exit()\n",
    "\n",
    "# create a window called \"MyVideo0\"\n",
    "cv2.namedWindow(\"Webcam\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "# read a new frame from video\n",
    "ret, frame0 = cap.read()\n",
    "if not ret:\n",
    "    print(\"Cannot read a frame from video stream\")\n",
    "\n",
    "# show the frame in \"Webcam\" window\n",
    "cv2.imshow(\"Webcam\", frame0)\n",
    "\n",
    "my_motion_history = []\n",
    "fMH1 = np.zeros(np.shape(frame0)[:-1], dtype=np.uint8)\n",
    "fMH2 = np.zeros(np.shape(frame0)[:-1], dtype=np.uint8)\n",
    "fMH3 = np.zeros(np.shape(frame0)[:-1], dtype=np.uint8)\n",
    "fMH4 = np.zeros(np.shape(frame0)[:-1], dtype=np.uint8)\n",
    "my_motion_history.append(fMH1)\n",
    "my_motion_history.append(fMH2)\n",
    "my_motion_history.append(fMH3)\n",
    "my_motion_history.append(fMH4)\n",
    "\n",
    "\n",
    "while(1):\n",
    "    # read a new frame from video\n",
    "    ret, frame = cap.read()\n",
    "    # if not successful, break loop\n",
    "    if not ret:\n",
    "        print(\"Cannot read a frame from video stream\")\n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"Webcam\", frame)\n",
    "\n",
    "    # Skin color detection\n",
    "    frame_dst = my_skin_detect(frame)\n",
    "    cv2.imshow(\"Skin\", frame_dst)\n",
    "    \n",
    "    # Find the largest object and create box for it\n",
    "    contours, cx, cy = boundingbox(frame_dst)\n",
    "    cv2.namedWindow(\"Result\", cv2.WINDOW_AUTOSIZE)\n",
    "    \n",
    "    # Template matching for detecting different gestures\n",
    "    ans = my_template_match(frame_dst)\n",
    "    \n",
    "    # Display the detection decision on the window\n",
    "    cv2.putText(contours,ans,(100,300),cv2.FONT_HERSHEY_SIMPLEX,5,(255,255,255),5)\n",
    "    \n",
    "    # Background differencing\n",
    "\n",
    "    # call my_frame_differencing function\n",
    "    frame_dst = my_frame_differencing(frame0, frame)\n",
    "    \n",
    "    # Visualizing motion history\n",
    "    my_motion_history.pop(0)\n",
    "    my_motion_history.append(frame_dst)\n",
    "    \n",
    "    # call my_motion_energy function\n",
    "    myMH = my_motion_energy(my_motion_history)\n",
    "    frame0 = frame\n",
    "    \n",
    "    # motion detecting\n",
    "    if(myMH.any() == True):\n",
    "        cv2.putText(contours,\"moving\",(900,300),cv2.FONT_HERSHEY_SIMPLEX,2,(255,255,255),2)\n",
    "\n",
    "    cv2.imshow(\"Results\", contours)\n",
    "    # wait for 'esc' key press for 30ms. If 'esc' key is pressed, break loop\n",
    "    if cv2.waitKey(30) == 27:\n",
    "        print(\"esc key is pressed by user\")\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-creativity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-ethiopia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
